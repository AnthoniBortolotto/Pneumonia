{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3, ResNet50, DenseNet121\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define as pastas de treino, validação e teste\n",
    "base_dir = 'chest_xray'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255) # Normaliza as imagens\n",
    "\n",
    "train_generator = datagen.flow_from_directory(train_dir,\n",
    "                                              target_size=(224, 224),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='binary') # Define o tamanho das imagens e o tamanho do batch de treino\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(validation_dir,\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='binary') # Define o tamanho das imagens e o tamanho do batch de validação\n",
    "\n",
    "test_generator = datagen.flow_from_directory(test_dir,\n",
    "                                             target_size=(224, 224),\n",
    "                                             batch_size=32,\n",
    "                                             class_mode='binary',\n",
    "                                             shuffle=False) # Define o tamanho das imagens e o tamanho do batch de teste, além de não embaralhar as imagens\n",
    "\n",
    "# Definindo a função para criar modelos\n",
    "def create_model(base_model):\n",
    "    model = models.Sequential() # Cria um modelo sequencial\n",
    "    model.add(base_model)     # Adiciona a arquitetura pré-treinada\n",
    "    model.add(layers.Flatten()) # Adiciona uma camada de achatamento\n",
    "    model.add(layers.Dense(256, activation='relu')) # Adiciona uma camada densa com 256 neurônios\n",
    "    model.add(layers.Dropout(0.5)) # Adiciona uma camada de dropout com 50% de chance\n",
    "    model.add(layers.Dense(1, activation='sigmoid')) # Adiciona uma camada densa com 1 neurônio e função de ativação sigmoid\n",
    "\n",
    "    return model\n",
    "\n",
    "# Criando modelos com base nas arquiteturas pré-treinadas\n",
    "vgg16_model = create_model(VGG16(weights='imagenet',\n",
    "                                 include_top=False,\n",
    "                                 input_shape=(224, 224, 3))) # Define a arquitetura VGG16 com pesos do ImageNet e sem a camada densa de classificação\n",
    "\n",
    "inception_model = create_model(InceptionV3(weights='imagenet',\n",
    "                                           include_top=False,\n",
    "                                           input_shape=(224, 224, 3))) # Define a arquitetura InceptionV3 com pesos do ImageNet e sem a camada densa de classificação\n",
    "\n",
    "resnet_model = create_model(ResNet50(weights='imagenet',\n",
    "                                     include_top=False,\n",
    "                                     input_shape=(224, 224, 3))) # Define a arquitetura ResNet50 com pesos do ImageNet e sem a camada densa de classificação\n",
    "\n",
    "densenet_model = create_model(DenseNet121(weights='imagenet',\n",
    "                                          include_top=False,\n",
    "                                          input_shape=(224, 224, 3))) # Define a arquitetura DenseNet121 com pesos do ImageNet e sem a camada densa de classificação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image  # Evita um erro de incompatibilidade entre o Pillow e o Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2816729875.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    conda uninstall PIL\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Se der erro, executar os comandos abaixo\n",
    "conda uninstall PIL\n",
    "conda uninstall Pillow\n",
    "conda install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "163/163 [==============================] - 1085s 7s/step - loss: 0.1928 - acc: 0.9155 - val_loss: 0.0482 - val_acc: 1.0000\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 1068s 7s/step - loss: 0.0743 - acc: 0.9735 - val_loss: 0.0424 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 1063s 7s/step - loss: 0.0644 - acc: 0.9789 - val_loss: 0.1454 - val_acc: 0.9375\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 1059s 6s/step - loss: 0.0542 - acc: 0.9804 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 1059s 6s/step - loss: 0.0302 - acc: 0.9887 - val_loss: 0.2282 - val_acc: 0.8750\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 1058s 6s/step - loss: 0.0372 - acc: 0.9864 - val_loss: 0.0301 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 1056s 6s/step - loss: 0.0197 - acc: 0.9931 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 1102s 7s/step - loss: 0.0172 - acc: 0.9927 - val_loss: 1.2337e-04 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 1058s 6s/step - loss: 0.0176 - acc: 0.9933 - val_loss: 4.1495e-04 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 1056s 6s/step - loss: 0.0117 - acc: 0.9958 - val_loss: 8.0672e-05 - val_acc: 1.0000\n",
      "Epoch 1/10\n",
      "163/163 [==============================] - 410s 2s/step - loss: 0.1363 - acc: 0.9500 - val_loss: 2.3917 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 402s 2s/step - loss: 0.0275 - acc: 0.9898 - val_loss: 2.1277 - val_acc: 0.6250\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 402s 2s/step - loss: 0.0172 - acc: 0.9937 - val_loss: 1.7740 - val_acc: 0.6875\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 411s 3s/step - loss: 0.0162 - acc: 0.9939 - val_loss: 0.0125 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 474s 3s/step - loss: 0.0190 - acc: 0.9937 - val_loss: 0.3524 - val_acc: 0.8750\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 487s 3s/step - loss: 0.0140 - acc: 0.9946 - val_loss: 1.2593 - val_acc: 0.7500\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 475s 3s/step - loss: 0.0065 - acc: 0.9977 - val_loss: 1.4526 - val_acc: 0.7500\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 479s 3s/step - loss: 0.0231 - acc: 0.9929 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 476s 3s/step - loss: 0.0059 - acc: 0.9979 - val_loss: 0.2195 - val_acc: 0.8750\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 479s 3s/step - loss: 0.0078 - acc: 0.9971 - val_loss: 3.0701 - val_acc: 0.6875\n",
      "Epoch 1/10\n",
      "163/163 [==============================] - 788s 5s/step - loss: 0.1526 - acc: 0.9624 - val_loss: 5.1843 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 764s 5s/step - loss: 0.0217 - acc: 0.9927 - val_loss: 4.3254 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 652s 4s/step - loss: 0.0132 - acc: 0.9950 - val_loss: 6.1247 - val_acc: 0.5000\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 642s 4s/step - loss: 0.0228 - acc: 0.9937 - val_loss: 13.0604 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 646s 4s/step - loss: 0.0243 - acc: 0.9923 - val_loss: 4.0590 - val_acc: 0.5625\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 643s 4s/step - loss: 0.0063 - acc: 0.9977 - val_loss: 1.2037 - val_acc: 0.8125\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 644s 4s/step - loss: 0.0130 - acc: 0.9956 - val_loss: 2.7697 - val_acc: 0.5625\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 648s 4s/step - loss: 0.0107 - acc: 0.9971 - val_loss: 2.7342 - val_acc: 0.5625\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 647s 4s/step - loss: 0.0026 - acc: 0.9992 - val_loss: 2.7392 - val_acc: 0.6875\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 648s 4s/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.6937 - val_acc: 0.8750\n",
      "Epoch 1/10\n",
      "163/163 [==============================] - 826s 5s/step - loss: 0.1231 - acc: 0.9618 - val_loss: 0.7473 - val_acc: 0.8125\n",
      "Epoch 2/10\n",
      "163/163 [==============================] - 806s 5s/step - loss: 0.0333 - acc: 0.9893 - val_loss: 0.2242 - val_acc: 0.9375\n",
      "Epoch 3/10\n",
      "163/163 [==============================] - 804s 5s/step - loss: 0.0197 - acc: 0.9927 - val_loss: 1.5069 - val_acc: 0.6875\n",
      "Epoch 4/10\n",
      "163/163 [==============================] - 804s 5s/step - loss: 0.0188 - acc: 0.9931 - val_loss: 1.6663 - val_acc: 0.6250\n",
      "Epoch 5/10\n",
      "163/163 [==============================] - 806s 5s/step - loss: 0.0142 - acc: 0.9942 - val_loss: 0.1362 - val_acc: 0.9375\n",
      "Epoch 6/10\n",
      "163/163 [==============================] - 803s 5s/step - loss: 0.0420 - acc: 0.9898 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "163/163 [==============================] - 781s 5s/step - loss: 0.0138 - acc: 0.9958 - val_loss: 5.6127 - val_acc: 0.5000\n",
      "Epoch 8/10\n",
      "163/163 [==============================] - 784s 5s/step - loss: 0.0214 - acc: 0.9935 - val_loss: 0.0525 - val_acc: 0.9375\n",
      "Epoch 9/10\n",
      "163/163 [==============================] - 783s 5s/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "163/163 [==============================] - 783s 5s/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0216 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Função para compilar e treinar o modelo\n",
    "def compile_and_train(model, train_generator, validation_generator, epochs=10):\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['acc']) # Compila o modelo com a função de perda binary_crossentropy, otimizador Adam e métrica de acurácia\n",
    "    history = model.fit(train_generator, epochs=epochs, validation_data=validation_generator) # Treina o modelo com os dados de treino e validação\n",
    "    return model, history\n",
    "\n",
    "# Treinando os modelos\n",
    "vgg16_model, vgg16_history = compile_and_train(vgg16_model, train_generator, validation_generator)\n",
    "inception_model, inception_history = compile_and_train(inception_model, train_generator, validation_generator)\n",
    "resnet_model, resnet_history = compile_and_train(resnet_model, train_generator, validation_generator)\n",
    "densenet_model, densenet_history = compile_and_train(densenet_model, train_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16:\n",
      "20/20 [==============================] - 30s 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.95      0.41      0.57       234\n",
      "   Pneumonia       0.74      0.99      0.84       390\n",
      "\n",
      "    accuracy                           0.77       624\n",
      "   macro avg       0.84      0.70      0.71       624\n",
      "weighted avg       0.82      0.77      0.74       624\n",
      "\n",
      "InceptionV3:\n",
      "20/20 [==============================] - 10s 424ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.98      0.23      0.37       234\n",
      "   Pneumonia       0.68      1.00      0.81       390\n",
      "\n",
      "    accuracy                           0.71       624\n",
      "   macro avg       0.83      0.61      0.59       624\n",
      "weighted avg       0.79      0.71      0.64       624\n",
      "\n",
      "ResNet50:\n",
      "20/20 [==============================] - 18s 828ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      0.04      0.08       234\n",
      "   Pneumonia       0.64      1.00      0.78       390\n",
      "\n",
      "    accuracy                           0.64       624\n",
      "   macro avg       0.82      0.52      0.43       624\n",
      "weighted avg       0.77      0.64      0.52       624\n",
      "\n",
      "DenseNet121:\n",
      "20/20 [==============================] - 20s 899ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.99      0.51      0.67       234\n",
      "   Pneumonia       0.77      1.00      0.87       390\n",
      "\n",
      "    accuracy                           0.81       624\n",
      "   macro avg       0.88      0.75      0.77       624\n",
      "weighted avg       0.85      0.81      0.80       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Função para avaliar o modelo\n",
    "def evaluate_model(model, test_generator):\n",
    "    test_generator.reset() # Reseta o gerador de teste\n",
    "    predictions = model.predict(test_generator) # Faz as predições com o gerador de teste\n",
    "    y_pred = np.round(predictions).astype(int) # Arredonda as predições para 0 ou 1\n",
    "    y_true = test_generator.classes # Obtém as classes verdadeiras\n",
    "    report = classification_report(y_true, y_pred, target_names=['Normal', 'Pneumonia']) # Cria o relatório de classificação\n",
    "    print(report) # Imprime o relatório\n",
    "\n",
    "# Avaliando os modelos\n",
    "print(\"VGG16:\")\n",
    "evaluate_model(vgg16_model, test_generator)\n",
    "print(\"InceptionV3:\")\n",
    "evaluate_model(inception_model, test_generator)\n",
    "print(\"ResNet50:\")\n",
    "evaluate_model(resnet_model, test_generator)\n",
    "print(\"DenseNet121:\")\n",
    "evaluate_model(densenet_model, test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
